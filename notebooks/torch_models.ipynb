{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch models\n",
    "\n",
    "[PyTorch Vision - Using models from Hub](https://pytorch.org/vision/stable/models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as tv_models\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all TorchVision models:\n",
      "['alexnet', 'convnext_base', 'convnext_large', 'convnext_small', 'convnext_tiny', 'deeplabv3_mobilenet_v3_large', 'deeplabv3_resnet101', 'deeplabv3_resnet50', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_v2_l', 'efficientnet_v2_m', 'efficientnet_v2_s', 'fasterrcnn_mobilenet_v3_large_320_fpn', 'fasterrcnn_mobilenet_v3_large_fpn', 'fasterrcnn_resnet50_fpn', 'fasterrcnn_resnet50_fpn_v2', 'fcn_resnet101', 'fcn_resnet50', 'fcos_resnet50_fpn', 'googlenet', 'inception_v3', 'keypointrcnn_resnet50_fpn', 'lraspp_mobilenet_v3_large', 'maskrcnn_resnet50_fpn', 'maskrcnn_resnet50_fpn_v2', 'maxvit_t', 'mc3_18', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'mobilenet_v3_large', 'mobilenet_v3_small', 'mvit_v1_b', 'mvit_v2_s', 'quantized_googlenet', 'quantized_inception_v3', 'quantized_mobilenet_v2', 'quantized_mobilenet_v3_large', 'quantized_resnet18', 'quantized_resnet50', 'quantized_resnext101_32x8d', 'quantized_resnext101_64x4d', 'quantized_shufflenet_v2_x0_5', 'quantized_shufflenet_v2_x1_0', 'quantized_shufflenet_v2_x1_5', 'quantized_shufflenet_v2_x2_0', 'r2plus1d_18', 'r3d_18', 'raft_large', 'raft_small', 'regnet_x_16gf', 'regnet_x_1_6gf', 'regnet_x_32gf', 'regnet_x_3_2gf', 'regnet_x_400mf', 'regnet_x_800mf', 'regnet_x_8gf', 'regnet_y_128gf', 'regnet_y_16gf', 'regnet_y_1_6gf', 'regnet_y_32gf', 'regnet_y_3_2gf', 'regnet_y_400mf', 'regnet_y_800mf', 'regnet_y_8gf', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext101_64x4d', 'resnext50_32x4d', 'retinanet_resnet50_fpn', 'retinanet_resnet50_fpn_v2', 's3d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'ssd300_vgg16', 'ssdlite320_mobilenet_v3_large', 'swin_b', 'swin_s', 'swin_t', 'swin_v2_b', 'swin_v2_s', 'swin_v2_t', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'vit_b_16', 'vit_b_32', 'vit_h_14', 'vit_l_16', 'vit_l_32', 'wide_resnet101_2', 'wide_resnet50_2']\n",
      "classify models:\n",
      "['alexnet', 'convnext_base', 'convnext_large', 'convnext_small', 'convnext_tiny', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_v2_l', 'efficientnet_v2_m', 'efficientnet_v2_s', 'googlenet', 'inception_v3', 'maxvit_t', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'mobilenet_v3_large', 'mobilenet_v3_small', 'regnet_x_16gf', 'regnet_x_1_6gf', 'regnet_x_32gf', 'regnet_x_3_2gf', 'regnet_x_400mf', 'regnet_x_800mf', 'regnet_x_8gf', 'regnet_y_128gf', 'regnet_y_16gf', 'regnet_y_1_6gf', 'regnet_y_32gf', 'regnet_y_3_2gf', 'regnet_y_400mf', 'regnet_y_800mf', 'regnet_y_8gf', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext101_64x4d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'swin_b', 'swin_s', 'swin_t', 'swin_v2_b', 'swin_v2_s', 'swin_v2_t', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'vit_b_16', 'vit_b_32', 'vit_h_14', 'vit_l_16', 'vit_l_32', 'wide_resnet101_2', 'wide_resnet50_2']\n"
     ]
    }
   ],
   "source": [
    "all_models = tv_models.list_models()\n",
    "\n",
    "print(f'all TorchVision models:\\n{all_models}')\n",
    "\n",
    "cls_models = tv_models.list_models(module=torchvision.models)\n",
    "\n",
    "print(f'classify models:\\n{cls_models}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/zhangjw/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'swin3d_b' from 'torchvision.models.video' (/home/zhangjw/miniconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/models/video/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# efn_v2_m = tv_models.get_model('efficientnet_v2_m', weights=\"DEFAULT\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m#print(efn_v2_m)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m efn_v2_m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mhub\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mpytorch/vision\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mefficientnet_v2_m\u001b[39;49m\u001b[39m\"\u001b[39;49m, weights\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mIMAGENET1K_V2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# weight_enum = torch.hub.load(\"pytorch/vision\", \"get_model_weights\", name=\"efficientnet_v2_m\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# print([weight for weight in weight_enum])\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/hub.py:542\u001b[0m, in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgithub\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    539\u001b[0m     repo_or_dir \u001b[39m=\u001b[39m _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, \u001b[39m\"\u001b[39m\u001b[39mload\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    540\u001b[0m                                        verbose\u001b[39m=\u001b[39mverbose, skip_validation\u001b[39m=\u001b[39mskip_validation)\n\u001b[0;32m--> 542\u001b[0m model \u001b[39m=\u001b[39m _load_local(repo_or_dir, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    543\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/hub.py:569\u001b[0m, in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, hubconf_dir)\n\u001b[1;32m    568\u001b[0m hubconf_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(hubconf_dir, MODULE_HUBCONF)\n\u001b[0;32m--> 569\u001b[0m hub_module \u001b[39m=\u001b[39m _import_module(MODULE_HUBCONF, hubconf_path)\n\u001b[1;32m    571\u001b[0m entry \u001b[39m=\u001b[39m _load_entry_from_hubconf(hub_module, model)\n\u001b[1;32m    572\u001b[0m model \u001b[39m=\u001b[39m entry(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/hub.py:90\u001b[0m, in \u001b[0;36m_import_module\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m     88\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mmodule_from_spec(spec)\n\u001b[1;32m     89\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(spec\u001b[39m.\u001b[39mloader, Loader)\n\u001b[0;32m---> 90\u001b[0m spec\u001b[39m.\u001b[39;49mloader\u001b[39m.\u001b[39;49mexec_module(module)\n\u001b[1;32m     91\u001b[0m \u001b[39mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:790\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.cache/torch/hub/pytorch_vision_main/hubconf.py:74\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mswin_transformer\u001b[39;00m \u001b[39mimport\u001b[39;00m swin_b, swin_s, swin_t, swin_v2_b, swin_v2_s, swin_v2_t\n\u001b[1;32m     73\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvgg\u001b[39;00m \u001b[39mimport\u001b[39;00m vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, vgg19_bn\n\u001b[0;32m---> 74\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvideo\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     75\u001b[0m     mc3_18,\n\u001b[1;32m     76\u001b[0m     mvit_v1_b,\n\u001b[1;32m     77\u001b[0m     mvit_v2_s,\n\u001b[1;32m     78\u001b[0m     r2plus1d_18,\n\u001b[1;32m     79\u001b[0m     r3d_18,\n\u001b[1;32m     80\u001b[0m     s3d,\n\u001b[1;32m     81\u001b[0m     swin3d_b,\n\u001b[1;32m     82\u001b[0m     swin3d_s,\n\u001b[1;32m     83\u001b[0m     swin3d_t,\n\u001b[1;32m     84\u001b[0m )\n\u001b[1;32m     85\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvision_transformer\u001b[39;00m \u001b[39mimport\u001b[39;00m vit_b_16, vit_b_32, vit_h_14, vit_l_16, vit_l_32\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'swin3d_b' from 'torchvision.models.video' (/home/zhangjw/miniconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/models/video/__init__.py)"
     ]
    }
   ],
   "source": [
    "# efn_v2_m = tv_models.get_model('efficientnet_v2_m', weights=\"DEFAULT\")\n",
    "\n",
    "#print(efn_v2_m)\n",
    "\n",
    "efn_v2_m = torch.hub.load(\"pytorch/vision\", \"efficientnet_v2_m\", weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "# weight_enum = torch.hub.load(\"pytorch/vision\", \"get_model_weights\", name=\"efficientnet_v2_m\")\n",
    "# print([weight for weight in weight_enum])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.__dict__['efficientnet_v2_m'](weights='IMAGENET1K_V1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f8529872f4e4281f943ea82f1273bb27c3a4c8cc197dcdd786f86f3b1491f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
